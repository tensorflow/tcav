{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running TCAV\n",
    "\n",
    "\n",
    "This notebook walks you through things you need to run TCAV. \n",
    "\n",
    "Before running this notebook, run the following to download all the data.\n",
    "\n",
    "```\n",
    "cd tcav/tcav_examples/image_models/imagenet\n",
    "\n",
    "python download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=50 --number_of_random_folders=3\n",
    "```\n",
    "\n",
    "In high level, you need:\n",
    "\n",
    "1. **example images in each folder** (you have this if you ran the above)\n",
    " * images for each concept\n",
    " * images for the class/labels of interest\n",
    " * random images that will be negative examples when learning CAVs (images that probably don't belong to any concepts)\n",
    "2. **model wrapper** (below uses example from tcav/model.py)\n",
    " * an instance of  ModelWrapper abstract class (in model.py). This tells TCAV class (tcav.py) how to communicate with your model (e.g., getting internal tensors)\n",
    "3. **act_generator** (below uses example from tcav/activation_generator.py)\n",
    " * an instance of ActivationGeneratorInterface that tells TCAV class how to load example data and how to get activations from the model\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "    pip install the tcav and tensorflow packages (or tensorflow-gpu if using GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Store concept and target class images to local folders\n",
    "\n",
    "and tell TCAV where they are.\n",
    "\n",
    "**source_dir**: where images of concepts, target class and random images (negative samples when learning CAVs) live. Each should be a sub-folder within this directory.\n",
    "\n",
    "Note that random image directories can be in any name. In this example, we are using `random500_0`, `random500_1`,.. for an arbitrary reason. \n",
    "\n",
    "You need roughly 50-200 images per concept and target class (10-20 pictures also tend to work, but 200 is pretty safe).\n",
    "\n",
    "\n",
    "**cav_dir**: directory to store CAVs (`None` if you don't want to store)\n",
    "\n",
    "**target, concept**: names of the target class (that you want to investigate) and concepts (strings) - these are folder names in source_dir\n",
    "\n",
    "**bottlenecks**: list of bottleneck names (intermediate layers in your model) that you want to use for TCAV. These names are defined in the model wrapper below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMEMBER TO UPDATE FOLDER PREFIX!\n"
     ]
    }
   ],
   "source": [
    "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
    "\n",
    "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
    "model_to_run = 'GoogleNet'  \n",
    "user = 'beenkim'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test'\n",
    "working_dir = \"/tmp/\" + user + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir+ '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live. \n",
    "source_dir = YOUR_PATH\n",
    "bottlenecks = [ 'mixed4c']  # @param \n",
    "      \n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]   \n",
    "\n",
    "target = 'zebra'  \n",
    "concepts = [\"dotted\",\"striped\",\"zigzagged\"]   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Write your model wrapper\n",
    "\n",
    "Next step is to tell TCAV how to communicate with your model. See `model.GoogleNetWrapper_public ` for details.\n",
    "\n",
    "You can define a subclass of ModelWrapper abstract class to do this. Let me walk you thru what each function does (tho they are pretty self-explanatory).  This wrapper includes a lot of the functions that you already have, for example, `get_prediction`.\n",
    "\n",
    "### 1. Tensors from the graph: bottleneck tensors and ends\n",
    "First, store your bottleneck tensors in `self.bottlenecks_tensors` as a dictionary. You only need bottlenecks that you are interested in running TCAV with. Similarly, fill in `self.ends` dictionary with `input`, `logit` and `prediction` tensors.\n",
    "\n",
    "### 2. Define loss\n",
    "Get your loss tensor, and assigned it to `self.loss`. This is what TCAV uses to take directional derivatives. \n",
    "\n",
    "While doing so, you would also want to set \n",
    "```python\n",
    "self.y_input \n",
    "```\n",
    "this simply is a tensorflow place holder for the target index in the logit layer (e.g., 0 index for a dog, 1 for a cat).\n",
    "For multi-class classification, typically something like this works:\n",
    "\n",
    "```python\n",
    "self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "```\n",
    "\n",
    "For example, for a multiclass classifier, something like below would work. \n",
    "\n",
    "```python\n",
    "    # Construct gradient ops.\n",
    "    with g.as_default():\n",
    "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
    "\n",
    "      self.loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(\n",
    "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
    "              logits=self.pred))\n",
    "    self._make_gradient_tensors()\n",
    "```\n",
    "\n",
    "### 3. Call _make_gradient_tensors in __init__() of your wrapper\n",
    "```python\n",
    "_make_gradient_tensors()  \n",
    "```\n",
    "does what you expect - given the loss and bottleneck tensors defined above, it adds gradient tensors.\n",
    "\n",
    "### 4. Fill in labels, image shapes and a model name.\n",
    "Get the mapping from labels (strings) to indice in the logit layer (int) in a dictionary format.\n",
    "\n",
    "```python\n",
    "def id_to_label(self, idx)\n",
    "def label_to_id(self, label)\n",
    "```\n",
    "\n",
    "Set your input image shape at  `self.image_shape`\n",
    "\n",
    "\n",
    "Set your model name to `self.model_name`\n",
    "\n",
    "You are done with writing the model wrapper! I wrote two model wrapers, InceptionV3 and Googlenet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**sess**: a tensorflow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/beenkim/git_google/brodenfetcher_test/tcav/tcav/model.py:312: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/beenkim/git_google/brodenfetcher_test/tcav/tcav/model.py:318: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/beenkim/git_google/brodenfetcher_test/tcav/tcav/model.py:301: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/beenkim/git_google/brodenfetcher_test/tcav/tcav/model.py:271: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = utils.create_session()\n",
    "\n",
    "# GRAPH_PATH is where the trained model is stored.\n",
    "GRAPH_PATH = source_dir + \"/inception5h/tensorflow_inception_graph.pb\"\n",
    "# LABEL_PATH is where the labels are stored. Each line contains one class, and they are ordered with respect to their index in \n",
    "# the logit layer. (yes, id_to_label function in the model wrapper reads from this file.)\n",
    "# For example, imagenet_comp_graph_label_strings.txt looks like:\n",
    "# dummy                                                                                      \n",
    "# kit fox\n",
    "# English setter\n",
    "# Siberian husky ...\n",
    "\n",
    "LABEL_PATH = source_dir + \"/inception5h/imagenet_comp_graph_label_strings.txt\"\n",
    "\n",
    "mymodel = model.GoogleNetWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Implement a class that returns activations (maybe with caching!)\n",
    "\n",
    "Lastly, you will implement a class of the ActivationGenerationInterface which TCAV uses to load example data for a given concept or target, call into your model wrapper and return activations. I pulled out this logic outside of mymodel because this step often takes the longest. By making it modular, you can cache your activations and/or parallelize your computations, as I have done in `ActivationGeneratorBase.process_and_load_activations` in `activation_generator.py`.\n",
    "\n",
    "\n",
    "The `process_and_load_activations` method of the activation generator must return a dictionary of activations that has concept or target name as  a first key, and the bottleneck name as a second key. So something like:\n",
    "\n",
    "```python\n",
    "{concept1: {bottleneck1: [[0.2, 0.1, ....]]},\n",
    "concept2: {bottleneck1: [[0.1, 0.02, ....]]},\n",
    "target1: {bottleneck1: [[0.02, 0.99, ....]]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You are ready to run TCAV!\n",
    "\n",
    "Let's do it.\n",
    "\n",
    "**num_random_exp**: number of experiments to confirm meaningful concept direction. TCAV will search for this many folders named `random500_0`, `random500_1`, etc. You can alternatively set the `random_concepts` keyword to be a list of folders of random concepts. Run at least 10-20 for meaningful tests. \n",
    "\n",
    "**random_counterpart**: as well as the above, you can optionally supply a single folder with random images as the \"positive set\" for statistical testing. Reduces computation time at the cost of less reliable random TCAV scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/beenkim/git_google/brodenfetcher_test/tcav/tcav/tcav.py:394: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "This may take a while... Go get coffee!\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(0)\n",
    "num_random_exp=3\n",
    "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
    "mytcav = tcav.TCAV(sess,\n",
    "                   target,\n",
    "                   concepts,\n",
    "                   bottlenecks,\n",
    "                   act_generator,\n",
    "                   alphas,\n",
    "                   cav_dir=cav_dir,\n",
    "                   num_random_exp=num_random_exp)#10)\n",
    "print ('This may take a while... Go get coffee!')\n",
    "results = mytcav.run(run_parallel=False)\n",
    "print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class = zebra\n",
      "  Concept = dotted\n",
      "    Bottleneck = mixed4c. TCAV Score = 0.60 (+- 0.14), random was 0.52 (+- 0.16). p-val = 0.551 (not significant)\n",
      "  Concept = striped\n",
      "    Bottleneck = mixed4c. TCAV Score = 0.99 (+- 0.01), random was 0.52 (+- 0.16). p-val = 0.003 (significant)\n",
      "  Concept = zigzagged\n",
      "    Bottleneck = mixed4c. TCAV Score = 0.81 (+- 0.08), random was 0.52 (+- 0.16). p-val = 0.037 (significant)\n",
      "{'mixed4c': {'bn_vals': [0.01, 0.9912280701754387, 0.8070175438596491], 'bn_stds': [0, 0.012405382126079766, 0.07545899357054936], 'significant': [False, True, True]}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_plot.plot_results(results, num_random_exp=num_random_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcavenv",
   "language": "python",
   "name": "tcavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
