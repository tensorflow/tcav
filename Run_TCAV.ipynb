{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v88fM4ciYYde"
      },
      "source": [
        "# Running TCAV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-RlU8wNYYdj"
      },
      "source": [
        "This notebook walks you through an example application of the TCAV library step-by-step to understand which human interpretable concepts (e.g. stripes, dots, zigzags) are important to the image classifier GoogleNet's (a.k.a. Inception v1) prediction of Zebras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1zIj8-aYYdj"
      },
      "source": [
        "## Install required packages\n",
        "\n",
        "To run through this notebook in the interim, you are encouraged to utilize a `virtualenv` or `conda` environment for installing and working with the required packages to avoid any dependency and compatability issues with different versions of packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sIHww5CuYYdk",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/site-packages (2.9.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow) (60.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorflow) (3.19.4)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/site-packages (from tensorflow) (4.0.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.9/site-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.22.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/site-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.11.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
            "Requirement already satisfied: tcav in /usr/local/lib/python3.9/site-packages (0.2.2)\n",
            "Requirement already satisfied: Pillow>=6.0.0 in /usr/local/lib/python3.9/site-packages (from tcav) (9.2.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.9/site-packages (from tcav) (1.9.1)\n",
            "Requirement already satisfied: protobuf>=3.10.0 in /usr/local/lib/python3.9/site-packages (from tcav) (3.19.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.9/site-packages (from tcav) (1.1.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.4 in /usr/local/lib/python3.9/site-packages (from tcav) (3.5.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from matplotlib>=2.2.4->tcav) (1.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/site-packages (from matplotlib>=2.2.4->tcav) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib>=2.2.4->tcav) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib>=2.2.4->tcav) (4.37.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib>=2.2.4->tcav) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/site-packages (from matplotlib>=2.2.4->tcav) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from matplotlib>=2.2.4->tcav) (21.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.20.3->tcav) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.20.3->tcav) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2.4->tcav) (1.16.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow\n",
        "%pip install tcav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NT91qkMYYdk"
      },
      "source": [
        "## Download example models and images\n",
        "\n",
        "Open a terminal and run the following commands:\n",
        "\n",
        "```\n",
        "cd tcav/tcav_examples/image_models/imagenet\n",
        "\n",
        "python download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=50 --number_of_random_folders=3\n",
        "```\n",
        "\n",
        "This script will download the following content into separate folders into a directory you specify with the `--source_dir=` argument:\n",
        "\n",
        "**Images**\n",
        "*  ImageNet images for the target Zebra class\n",
        "*  [Broden dataset](http://netdissect.csail.mit.edu/) images for three concepts (e.g. striped, dotted, zigzagged)\n",
        "*  Random ImageNet class images used by TCAV for hypothesis testing of important concepts\n",
        "\n",
        "**Models**\n",
        "*  [Inception 5h model](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/inception5h.py)\n",
        "*  [Mobilenet V2 model](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlrLUu4zYYdl"
      },
      "source": [
        "## Import extensions and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sS1ZjSZjYYdl"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U4yP9kDlYYdl"
      },
      "outputs": [],
      "source": [
        "import tcav.activation_generator as act_gen\n",
        "import tcav.cav as cav\n",
        "import tcav.model  as model\n",
        "import tcav.tcav as tcav\n",
        "import tcav.utils as utils\n",
        "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
        "import os \n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yitpnXmEYYdm"
      },
      "source": [
        "## TCAV step-by-step\n",
        "\n",
        "You will walk through the following steps below:\n",
        "\n",
        "1. **Store example images in each folder** (you have this if you ran the above)\n",
        " * images for each concept\n",
        " * images for the class/labels of interest\n",
        " * random images that will be negative examples when learning CAVs (images that probably don't belong to any concepts)\n",
        "2. **Write a model wrapper** (below uses example from tcav/model.py)\n",
        " * an instance of  ModelWrapper abstract class (in model.py). This tells TCAV class (tcav.py) how to communicate with your model (e.g., getting internal tensors)\n",
        "3. **Retrieve model activations** (below uses example from tcav/activation_generator.py)\n",
        " * an instance of ActivationGeneratorInterface that tells TCAV class how to load example data and how to get activations from the model\n",
        "4. Run TCAV and visualize scores for important concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjLK3pBYYdm"
      },
      "source": [
        "## Step 1: Store concept and target class images to local folders\n",
        "\n",
        "... and tell TCAV where they are.\n",
        "\n",
        "**source_dir**: where images of concepts, target class and random images (negative samples when learning CAVs) live. Each should be a sub-folder within this directory.\n",
        "\n",
        "Note that random image directories can be in any name. In this example, we are using `random500_0`, `random500_1`,.. for an arbitrary reason. \n",
        "\n",
        "You need roughly 50-200 images per concept and target class (10-20 pictures also tend to work, but 200 is pretty safe).\n",
        "\n",
        "\n",
        "**cav_dir**: directory to store CAVs (`None` if you don't want to store)\n",
        "\n",
        "**target, concept**: names of the target class (that you want to investigate) and concepts (strings) - these are folder names in source_dir\n",
        "\n",
        "**bottlenecks**: list of bottleneck names (intermediate layers in your model) that you want to use for TCAV. These names are defined in the model wrapper below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EHabMnMNYYdm",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REMEMBER TO UPDATE YOUR_PATH (where images, models are)!\n"
          ]
        }
      ],
      "source": [
        "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
        "\n",
        "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
        "model_to_run = 'GoogleNet'  \n",
        "user = 'mariaf'\n",
        "# the name of the parent directory that results are stored (only if you want to cache)\n",
        "project_name = 'tcav_class_test'\n",
        "working_dir = \"/tmp/\" + user + '/' + project_name\n",
        "# where activations are stored (only if your act_gen_wrapper does so)\n",
        "activation_dir =  working_dir+ '/activations/'\n",
        "# where CAVs are stored. \n",
        "# You can say None if you don't wish to store any.\n",
        "cav_dir = working_dir + '/cavs/'\n",
        "# where the images live.\n",
        "\n",
        "# TODO: replace 'YOUR_PATH' with path to downloaded models and images. \n",
        "source_dir = '/Users/maria/MastersThesis/tcav/ImageNet_Data'\n",
        "bottlenecks = ['mixed3a']  # @param \n",
        "      \n",
        "utils.make_dir_if_not_exists(activation_dir)\n",
        "utils.make_dir_if_not_exists(working_dir)\n",
        "utils.make_dir_if_not_exists(cav_dir)\n",
        "\n",
        "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
        "alphas = [0.1]   \n",
        "\n",
        "target = 'zebra'  \n",
        "concepts = [\"dotted\",\"striped\",\"zigzagged\"]  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_DfQqsAYYdn"
      },
      "source": [
        "## Step 2: Write your model wrapper\n",
        "\n",
        "The next step is to tell TCAV how to communicate with your model. See `model.GoogleNetWrapper_public ` for details.\n",
        "\n",
        "You can define a subclass of ModelWrapper abstract class to do this. Let me walk you thru what each function does (tho they are pretty self-explanatory).  This wrapper includes a lot of the functions that you already have, for example, `get_prediction`.\n",
        "\n",
        "### 2.1: Tensors from the graph: bottleneck tensors and ends\n",
        "First, store your bottleneck tensors in `self.bottlenecks_tensors` as a dictionary. You only need bottlenecks that you are interested in running TCAV with. Similarly, fill in `self.ends` dictionary with `input`, `logit` and `prediction` tensors.\n",
        "\n",
        "### 2.2: Define loss\n",
        "Get your loss tensor, and assigned it to `self.loss`. This is what TCAV uses to take directional derivatives. \n",
        "\n",
        "While doing so, you would also want to set \n",
        "```python\n",
        "self.y_input \n",
        "```\n",
        "this simply is a tensorflow place holder for the target index in the logit layer (e.g., 0 index for a dog, 1 for a cat).\n",
        "For multi-class classification, typically something like this works:\n",
        "\n",
        "```python\n",
        "self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
        "```\n",
        "\n",
        "For example, for a multiclass classifier, something like below would work. \n",
        "\n",
        "```python\n",
        "    # Construct gradient ops.\n",
        "    with g.as_default():\n",
        "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
        "\n",
        "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
        "\n",
        "      self.loss = tf.reduce_mean(\n",
        "          tf.nn.softmax_cross_entropy_with_logits(\n",
        "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
        "              logits=self.pred))\n",
        "    self._make_gradient_tensors()\n",
        "```\n",
        "\n",
        "### 2.3: Call _make_gradient_tensors in __init__() of your wrapper\n",
        "```python\n",
        "_make_gradient_tensors()  \n",
        "```\n",
        "does what you expect - given the loss and bottleneck tensors defined above, it adds gradient tensors.\n",
        "\n",
        "### 2.4: Fill in labels, image shapes and a model name.\n",
        "Get the mapping from labels (strings) to indice in the logit layer (int) in a dictionary format.\n",
        "\n",
        "```python\n",
        "def id_to_label(self, idx)\n",
        "def label_to_id(self, label)\n",
        "```\n",
        "\n",
        "Set your input image shape at  `self.image_shape`\n",
        "\n",
        "\n",
        "Set your model name to `self.model_name`\n",
        "\n",
        "You are done with writing the model wrapper! See the two example model wrapers, InceptionV3 and Googlenet in `tcav/model.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hH-YQiEIYYdn",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-07 13:20:47.066892: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Create TensorFlow session.\n",
        "sess = utils.create_session()\n",
        "\n",
        "# GRAPH_PATH is where the trained model is stored.\n",
        "GRAPH_PATH = source_dir + \"/inception5h/tensorflow_inception_graph.pb\"\n",
        "# LABEL_PATH is where the labels are stored. Each line contains one class, and they are ordered with respect to their index in \n",
        "# the logit layer. (yes, id_to_label function in the model wrapper reads from this file.)\n",
        "# For example, imagenet_comp_graph_label_strings.txt looks like:\n",
        "# dummy                                                                                      \n",
        "# kit fox\n",
        "# English setter\n",
        "# Siberian husky ...\n",
        "\n",
        "LABEL_PATH = source_dir + \"/inception5h/imagenet_comp_graph_label_strings.txt\"\n",
        "\n",
        "mymodel = model.GoogleNetWrapper_public(sess,\n",
        "                                        GRAPH_PATH,\n",
        "                                        LABEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY5kXbVAYYdo"
      },
      "source": [
        "## Step 3: Implement a class that returns activations (maybe with caching!)\n",
        "\n",
        "Lastly, you will implement a class of the ActivationGenerationInterface which TCAV uses to load example data for a given concept or target, call into your model wrapper and return activations. I pulled out this logic outside of mymodel because this step often takes the longest. By making it modular, you can cache your activations and/or parallelize your computations, as I have done in `ActivationGeneratorBase.process_and_load_activations` in `activation_generator.py`.\n",
        "\n",
        "\n",
        "The `process_and_load_activations` method of the activation generator must return a dictionary of activations that has concept or target name as  a first key, and the bottleneck name as a second key. So something like:\n",
        "\n",
        "```python\n",
        "{concept1: {bottleneck1: [[0.2, 0.1, ....]]},\n",
        "concept2: {bottleneck1: [[0.1, 0.02, ....]]},\n",
        "target1: {bottleneck1: [[0.02, 0.99, ....]]}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZmSyFxQbYYdo"
      },
      "outputs": [],
      "source": [
        "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uABCWhp8YYdo"
      },
      "source": [
        "## Step 4: Run TCAV and visualize concept importance\n",
        "\n",
        "You are now ready to run TCAV! Let's do it.\n",
        "\n",
        "**num_random_exp**: number of experiments to confirm meaningful concept direction. TCAV will search for this many folders named `random500_0`, `random500_1`, etc. You can alternatively set the `random_concepts` keyword to be a list of folders of random concepts. Run at least 10-20 for meaningful tests. \n",
        "\n",
        "**random_counterpart**: as well as the above, you can optionally supply a single folder with random images as the \"positive set\" for statistical testing. Reduces computation time at the cost of less reliable random TCAV scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F2FVOGSvYYdp",
        "scrolled": false,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:mixed3a ['dotted', 'random500_0'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['dotted', 'random500_1'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['dotted', 'random500_2'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['dotted', 'random500_3'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['striped', 'random500_0'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['striped', 'random500_1'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['striped', 'random500_2'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['striped', 'random500_3'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['zigzagged', 'random500_0'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['zigzagged', 'random500_1'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['zigzagged', 'random500_2'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['zigzagged', 'random500_3'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_0', 'random500_1'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_0', 'random500_2'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_0', 'random500_3'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_1', 'random500_0'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_1', 'random500_2'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_1', 'random500_3'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_2', 'random500_0'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_2', 'random500_1'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_2', 'random500_3'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_3', 'random500_0'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_3', 'random500_1'] zebra 0.1\n",
            "INFO:tensorflow:mixed3a ['random500_3', 'random500_2'] zebra 0.1\n",
            "INFO:tensorflow:TCAV will 24 params\n",
            "This may take a while... Go get coffee!\n",
            "INFO:tensorflow:running 24 params\n",
            "INFO:tensorflow:Running param 0 of 24\n",
            "INFO:tensorflow:running zebra ['dotted', 'random500_0']\n",
            "INFO:tensorflow:/tmp/mariafogh/tcav_class_test/activations/acts_dotted_mixed3a does not exist, Making one...\n",
            "INFO:tensorflow:/tmp/mariafogh/tcav_class_test/activations/acts_random500_0_mixed3a does not exist, Making one...\n",
            "INFO:tensorflow:cannot identify image file <tensorflow.python.platform.gfile.GFile object at 0x13fb55220>\n",
            "INFO:tensorflow:/tmp/mariafogh/tcav_class_test/activations/acts_zebra_mixed3a does not exist, Making one...\n",
            "INFO:tensorflow:Training CAV ['dotted', 'random500_0'] - mixed3a alpha 0.1\n",
            "INFO:tensorflow:training with alpha=0.1\n",
            "INFO:tensorflow:understand output min_data_points = 40\n",
            "INFO:tensorflow:understand output concept = dotted\n",
            "INFO:tensorflow:understand output bottleneck = mixed3a\n",
            "INFO:tensorflow:understand output acts.keys() = dict_keys(['dotted', 'random500_0'])\n",
            "INFO:tensorflow:understand output acts[concept][bottleneck].shape[0] = 50\n",
            "INFO:tensorflow:understand output min_data_points = 40\n",
            "INFO:tensorflow:understand output concept = random500_0\n",
            "INFO:tensorflow:understand output bottleneck = mixed3a\n",
            "INFO:tensorflow:understand output acts.keys() = dict_keys(['dotted', 'random500_0'])\n",
            "INFO:tensorflow:understand output acts[concept][bottleneck].shape[0] = 40\n",
            "INFO:tensorflow:acc per class {'dotted': 0.7692307692307693, 'random500_0': 0.9285714285714286, 'overall': 0.8518518518518519}\n",
            "INFO:tensorflow:CAV accuracies: {'dotted': 0.7692307692307693, 'random500_0': 0.9285714285714286, 'overall': 0.8518518518518519}\n",
            "INFO:tensorflow:cannot identify image file <tensorflow.python.platform.gfile.GFile object at 0x13fb02d30>\n",
            "INFO:tensorflow:cannot identify image file <tensorflow.python.platform.gfile.GFile object at 0x13fae4070>\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/bx/1rzxld1d3pdfks1bqj8dn3jw0000gn/T/ipykernel_11873/144921439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                    num_random_exp=num_random_exp)#10)\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'This may take a while... Go get coffee!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmytcav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/MastersThesis/tcav/tcav/tcav.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_workers, run_parallel, overwrite, return_proto)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# tf.compat.v1.logging.info(\"Hello: We are at %s\" % (vars(param))) #print parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 results.append(\n\u001b[0;32m--> 257\u001b[0;31m                     self._run_single_set(\n\u001b[0m\u001b[1;32m    258\u001b[0m                         \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_parallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                     )\n",
            "\u001b[0;32m~/MastersThesis/tcav/tcav/tcav.py\u001b[0m in \u001b[0;36m_run_single_set\u001b[0;34m(self, param, overwrite, run_parallel)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mcav_instance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcav_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mactivation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_examples_for_concept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         )\n\u001b[1;32m    337\u001b[0m         result = {\n",
            "\u001b[0;32m~/MastersThesis/tcav/tcav/activation_generator.py\u001b[0m in \u001b[0;36mget_examples_for_concept\u001b[0;34m(self, concept)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     ]\n\u001b[0;32m--> 118\u001b[0;31m     imgs = self.load_images_from_files(\n\u001b[0m\u001b[1;32m    119\u001b[0m         img_paths, self.max_examples, shape=self.model.get_image_shape()[:2])\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/MastersThesis/tcav/tcav/activation_generator.py\u001b[0m in \u001b[0;36mload_images_from_files\u001b[0;34m(self, filenames, max_imgs, do_shuffle, run_parallel, shape, num_workers)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_parallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       imgs = pool.map(\n\u001b[0m\u001b[1;32m    190\u001b[0m           \u001b[0;32mlambda\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m           filenames[:max_imgs])\n",
            "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.2_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.2_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.2_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.2_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.2_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import absl\n",
        "absl.logging.set_verbosity(0)\n",
        "num_random_exp=4\n",
        "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
        "mytcav = tcav.TCAV(sess,\n",
        "                   target,\n",
        "                   concepts,\n",
        "                   bottlenecks,\n",
        "                   act_generator,\n",
        "                   alphas,\n",
        "                   cav_dir=cav_dir,\n",
        "                   num_random_exp=num_random_exp)#10)\n",
        "print ('This may take a while... Go get coffee!')\n",
        "results = mytcav.run(run_parallel=False)\n",
        "print ('done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hjKVKa80YYdp",
        "outputId": "ff3cbebe-4edd-4342-cede-24dc10ce9d99",
        "scrolled": false,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class = zebra\n",
            "  Concept = dotted\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'mixed3a'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/bx/1rzxld1d3pdfks1bqj8dn3jw0000gn/T/ipykernel_11873/2088044462.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_random_exp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_random_exp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/MastersThesis/tcav/tcav/utils_plot.py\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(results, random_counterpart, random_concepts, num_random_exp, min_p_val)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Calculate statistical significance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttest_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_i_ups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_ups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbottleneck\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mixed3a'"
          ]
        }
      ],
      "source": [
        "utils_plot.plot_results(results, num_random_exp=num_random_exp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Run TCAV.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
